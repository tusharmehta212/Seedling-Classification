{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import (Dense, Dropout, Conv2D, GlobalAveragePooling2D, MaxPool2D, Flatten, Activation, Input, BatchNormalization)\n",
    "from keras.preprocessing. image import  ImageDataGenerator\n",
    "from keras.models import  Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "from load_test_seedling import load_test_data\n",
    "from load_seedling_data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SZ = 299 # Image height and width\n",
    "data_dir = '/home/tushar/Datasets/seedlingDataset/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pretrained VGG19 model on imagenet\n",
    "base_model = VGG19(include_top=False, weights='imagenet', input_shape=(SZ,SZ,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Global Average pooling layer and some dense layers and dropout with softmax output\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.6)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "prediction = Dense(12, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making model object for the new model\n",
    "model = Model(inputs = base_model.input, outputs = prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So only added layers are trainable\n",
    "for l in base_model.layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:43<00:00,  3.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loading the data using helper functions with 80 20 split\n",
    "x_train, y_train, x_valid, y_valid, class_dict, class_dict_inv = load_data(data_dir=data_dir,\n",
    "                                                                           sz=SZ,\n",
    "                                                                           train_split=.80,\n",
    "                                                                           rescale=1.255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3800 samples, validate on 950 samples\n",
      "Epoch 1/10\n",
      "3800/3800 [==============================] - 36s 9ms/step - loss: 3.9897 - acc: 0.2061 - val_loss: 2.0007 - val_acc: 0.4126\n",
      "Epoch 2/10\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 2.1798 - acc: 0.3047 - val_loss: 1.8668 - val_acc: 0.4579\n",
      "Epoch 3/10\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 1.8787 - acc: 0.3839 - val_loss: 1.5948 - val_acc: 0.5516\n",
      "Epoch 4/10\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 1.7033 - acc: 0.4258 - val_loss: 1.3561 - val_acc: 0.6316\n",
      "Epoch 5/10\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 1.5213 - acc: 0.4861 - val_loss: 1.1923 - val_acc: 0.6579\n",
      "Epoch 6/10\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 1.4354 - acc: 0.5079 - val_loss: 1.0659 - val_acc: 0.6916\n",
      "Epoch 7/10\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 1.3381 - acc: 0.5358 - val_loss: 0.9737 - val_acc: 0.7211\n",
      "Epoch 8/10\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 1.2619 - acc: 0.5632 - val_loss: 0.9287 - val_acc: 0.7200\n",
      "Epoch 9/10\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 1.2112 - acc: 0.5729 - val_loss: 0.8534 - val_acc: 0.7337\n",
      "Epoch 10/10\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 1.1539 - acc: 0.6026 - val_loss: 0.8185 - val_acc: 0.7747\n"
     ]
    }
   ],
   "source": [
    "# Training for 5 epochs\n",
    "info  = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"temp_vgg19\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"temp_vgg19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 299, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 299, 299, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 299, 299, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 149, 149, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 149, 149, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 149, 149, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 74, 74, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 74, 74, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 74, 74, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 37, 37, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 37, 37, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 37, 37, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 18, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 20,091,596\n",
      "Trainable params: 67,212\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning the model\n",
    "for l in model.layers[-10:]:\n",
    "    l.trainable = True\n",
    "# Setting a smaller learning rate so that weights are not changed a lot and using reducing lr on plateau and saving using checkpoint\n",
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose = 1, mode = 'auto', )\n",
    "msave = ModelCheckpoint('vgg19_model_checkpoint.hdf5', save_best_only=True)\n",
    "model.compile(opt, 'categorical_crossentropy', ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3800 samples, validate on 950 samples\n",
      "Epoch 1/50\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.9760 - acc: 0.6695 - val_loss: 0.4320 - val_acc: 0.8600\n",
      "Epoch 2/50\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.5462 - acc: 0.8153 - val_loss: 0.4314 - val_acc: 0.8389\n",
      "Epoch 3/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.3932 - acc: 0.8624 - val_loss: 0.3699 - val_acc: 0.8695\n",
      "Epoch 4/50\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.3336 - acc: 0.8847 - val_loss: 0.2702 - val_acc: 0.8958\n",
      "Epoch 5/50\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.2411 - acc: 0.9139 - val_loss: 0.2494 - val_acc: 0.9221\n",
      "Epoch 6/50\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.1958 - acc: 0.9318 - val_loss: 0.2666 - val_acc: 0.9084\n",
      "Epoch 7/50\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.1700 - acc: 0.9392 - val_loss: 0.2447 - val_acc: 0.9179\n",
      "Epoch 8/50\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.1427 - acc: 0.9513 - val_loss: 0.2495 - val_acc: 0.9179\n",
      "Epoch 9/50\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.1473 - acc: 0.9500 - val_loss: 0.2984 - val_acc: 0.8947\n",
      "Epoch 10/50\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.1063 - acc: 0.9613 - val_loss: 0.3435 - val_acc: 0.9074\n",
      "Epoch 11/50\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.1004 - acc: 0.9647 - val_loss: 0.2745 - val_acc: 0.8905\n",
      "Epoch 12/50\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.1264 - acc: 0.9608 - val_loss: 0.2958 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 13/50\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.0646 - acc: 0.9813 - val_loss: 0.2339 - val_acc: 0.9305\n",
      "Epoch 14/50\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.0447 - acc: 0.9853 - val_loss: 0.2244 - val_acc: 0.9379\n",
      "Epoch 15/50\n",
      "3800/3800 [==============================] - 29s 8ms/step - loss: 0.0303 - acc: 0.9908 - val_loss: 0.2350 - val_acc: 0.9421\n",
      "Epoch 16/50\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.0312 - acc: 0.9911 - val_loss: 0.2286 - val_acc: 0.9400\n",
      "Epoch 17/50\n",
      "3800/3800 [==============================] - 30s 8ms/step - loss: 0.0274 - acc: 0.9908 - val_loss: 0.2401 - val_acc: 0.9368\n",
      "Epoch 18/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0272 - acc: 0.9900 - val_loss: 0.2164 - val_acc: 0.9421\n",
      "Epoch 19/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0239 - acc: 0.9932 - val_loss: 0.2222 - val_acc: 0.9495\n",
      "Epoch 20/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0226 - acc: 0.9947 - val_loss: 0.2173 - val_acc: 0.9421\n",
      "Epoch 21/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0205 - acc: 0.9939 - val_loss: 0.2356 - val_acc: 0.9463\n",
      "Epoch 22/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0190 - acc: 0.9942 - val_loss: 0.2433 - val_acc: 0.9442\n",
      "Epoch 23/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0129 - acc: 0.9966 - val_loss: 0.2454 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 24/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0182 - acc: 0.9945 - val_loss: 0.2420 - val_acc: 0.9442\n",
      "Epoch 25/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0164 - acc: 0.9955 - val_loss: 0.2434 - val_acc: 0.9442\n",
      "Epoch 26/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0145 - acc: 0.9958 - val_loss: 0.2449 - val_acc: 0.9432\n",
      "Epoch 27/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0152 - acc: 0.9958 - val_loss: 0.2460 - val_acc: 0.9432\n",
      "Epoch 28/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0131 - acc: 0.9971 - val_loss: 0.2472 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 29/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.2467 - val_acc: 0.9453\n",
      "Epoch 30/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0169 - acc: 0.9945 - val_loss: 0.2461 - val_acc: 0.9453\n",
      "Epoch 31/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0147 - acc: 0.9961 - val_loss: 0.2463 - val_acc: 0.9453\n",
      "Epoch 32/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0141 - acc: 0.9966 - val_loss: 0.2461 - val_acc: 0.9453\n",
      "Epoch 33/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0138 - acc: 0.9974 - val_loss: 0.2464 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 34/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.2463 - val_acc: 0.9453\n",
      "Epoch 35/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0156 - acc: 0.9963 - val_loss: 0.2463 - val_acc: 0.9453\n",
      "Epoch 36/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0183 - acc: 0.9934 - val_loss: 0.2463 - val_acc: 0.9453\n",
      "Epoch 37/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0156 - acc: 0.9953 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "Epoch 38/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0154 - acc: 0.9953 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 39/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0157 - acc: 0.9961 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "Epoch 40/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0130 - acc: 0.9968 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "Epoch 41/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0157 - acc: 0.9966 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "Epoch 42/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0159 - acc: 0.9976 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "Epoch 43/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0155 - acc: 0.9950 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 44/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0132 - acc: 0.9966 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "Epoch 45/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0166 - acc: 0.9950 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "Epoch 46/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0177 - acc: 0.9950 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "Epoch 47/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0175 - acc: 0.9932 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "Epoch 48/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0129 - acc: 0.9974 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "Epoch 49/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0180 - acc: 0.9942 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "Epoch 50/50\n",
      "3800/3800 [==============================] - 31s 8ms/step - loss: 0.0148 - acc: 0.9958 - val_loss: 0.2462 - val_acc: 0.9453\n"
     ]
    }
   ],
   "source": [
    "# Training the model for 20 epochs\n",
    "info  = model.fit(x_train, \n",
    "                  y_train, \n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=50, \n",
    "                  validation_data=(x_valid, y_valid), \n",
    "                  callbacks=[lr_reduce, msave])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Future Upgrades</h1>\n",
    "1. Data Augmentation during training\n",
    "2. l2 Regularization\n",
    "3. Batch Norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
